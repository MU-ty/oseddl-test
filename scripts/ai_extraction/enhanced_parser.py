"""
å¢å¼ºå‹æ•°æ®è§£æå™¨ - è§„åˆ™ + LLM æ··åˆæå–
ä¼˜å…ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¶é—´ã€åœ°ç‚¹ã€é“¾æ¥ç­‰ç»“æ„åŒ–æ•°æ®
ç„¶åä½¿ç”¨ LLM è¡¥å……æè¿°ã€æ ‡ç­¾ç­‰éç»“æ„åŒ–æ•°æ®
"""

import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field

@dataclass
class TimelineEvent:
    deadline: str
    comment: str
    
    def to_dict(self) -> Dict:
        return {"deadline": self.deadline, "comment": self.comment}

@dataclass
class ActivityEvent:
    year: int
    id: str
    link: str
    timeline: List[TimelineEvent] = field(default_factory=list)
    timezone: str = "Asia/Shanghai"
    date: str = ""
    place: str = ""
    
    def to_dict(self) -> Dict:
        return {
            "year": self.year,
            "id": self.id,
            "link": self.link,
            "timeline": [t.to_dict() for t in self.timeline],
            "timezone": self.timezone,
            "date": self.date,
            "place": self.place
        }

@dataclass
class ParsedActivity:
    title: str
    description: str
    category: str
    tags: List[str] = field(default_factory=list)
    events: List[ActivityEvent] = field(default_factory=list)
    
    def to_dict(self) -> Dict:
        return {
            "title": self.title,
            "description": self.description,
            "category": self.category,
            "tags": self.tags,
            "events": [e.to_dict() for e in self.events]
        }

class EnhancedDataParser:
    """å¢å¼ºçš„æ•°æ®è§£æå™¨ - è§„åˆ™ + LLM"""
    
    def __init__(self):
        self.llm = None
        try:
            from github_models_parser import GitHubModelsParser
            from config import settings
            self.llm = GitHubModelsParser(settings.GITHUB_TOKEN, model="gpt-4o")
        except:
            pass
    
    def extract_time_info(self, text: str) -> Tuple[Optional[str], List[str]]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¶é—´ä¿¡æ¯"""
        
        # åŒ¹é… "2025å¹´11æœˆ11æ—¥ 09:30-11:30"
        patterns = [
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥[ï¼Œ,\s]*(\d{1,2}):(\d{2})\s*[-~]\s*(\d{1,2}):(\d{2})',
            r'(\d{4})-(\d{1,2})-(\d{1,2})\s*(\d{1,2}):(\d{2})\s*[-~]\s*(\d{1,2}):(\d{2})',
        ]
        
        timeline = []
        
        for pattern in patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                if len(match.groups()) >= 8:
                    year, month, day, h1, m1, h2, m2 = match.groups()[:7]
                    date_str = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                    time_str = f"{h1.zfill(2)}:{m1.zfill(2)}-{h2.zfill(2)}:{m2.zfill(2)}"
                    
                    timeline.append(TimelineEvent(
                        deadline=f"{year}-{month.zfill(2)}-{day.zfill(2)}T{h1.zfill(2)}:{m1.zfill(2)}:00Z",
                        comment=f"äº‹ä»¶æ—¶é—´: {time_str}"
                    ))
                    
                    return date_str, timeline
        
        return None, []
    
    def extract_place_info(self, text: str) -> Optional[str]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–åœ°ç‚¹ä¿¡æ¯"""
        
        patterns = [
            r'åœ°ç‚¹[ï¼š:]\s*([^\n]+)',
            r'åœ°å€[ï¼š:]\s*([^\n]+)',
            r'ä¸¾åŠåœ°[ï¼š:]\s*([^\n]+)',
            r'ä¸¾åŠåœ°ç‚¹[ï¼š:]\s*([^\n]+)',
            r'ğŸ“\s*([^\n]+)',
            r'Location[ï¼š:]\s*([^\n]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                place = match.group(1).strip()
                if place and len(place) > 2:
                    return place
        
        return None
    
    def extract_description(self, text: str) -> str:
        """æå–æ´»åŠ¨æè¿°"""
        
        # å–å‰ 200 ä¸ªå­—ç¬¦ä½œä¸ºæè¿°
        lines = text.split('\n')
        description = ''
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('æ—¶é—´') and not line.startswith('åœ°ç‚¹'):
                description += line + ' '
                if len(description) > 200:
                    break
        
        return description[:300] if description else 'æ´»åŠ¨ä¿¡æ¯'
    
    def extract_tags(self, title: str, text: str) -> List[str]:
        """è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾"""
        
        tags = []
        
        # åŸºäºæ ‡é¢˜å’Œå†…å®¹çš„å…³é”®è¯
        keywords = {
            'å¼€æº': ['å¼€æº', 'open source', 'opensource'],
            'æ ¡å›­': ['å¤§å­¦', 'é«˜æ ¡', 'æ ¡å›­', 'university', 'campus'],
            'ä¼šè®®': ['ä¼šè®®', 'conference', 'summit'],
            'ç«èµ›': ['ç«èµ›', 'competition', 'æ¯”èµ›', 'contest'],
            'è®²åº§': ['è®²åº§', 'talk', 'seminar'],
            'å·¥ä½œåŠ': ['å·¥ä½œåŠ', 'workshop', 'ç ”è®¨'],
        }
        
        combined_text = (title + ' ' + text).lower()
        
        for tag, keywords_list in keywords.items():
            for keyword in keywords_list:
                if keyword.lower() in combined_text:
                    tags.append(tag)
                    break
        
        return list(set(tags))[:5]  # æœ€å¤š 5 ä¸ªæ ‡ç­¾
    
    async def parse(self, extracted_text: str, source_url: str = None) -> ParsedActivity:
        """
        è§£ææå–çš„æ–‡æœ¬
        """
        
        # ç¬¬ 1 æ­¥ï¼šä½¿ç”¨ LLM è·å–æ ‡é¢˜å’Œåˆ†ç±»
        llm_result = await self._parse_with_llm(extracted_text)
        
        title = llm_result.get('title', 'æ´»åŠ¨')
        description = llm_result.get('description', '')
        category = llm_result.get('category', 'activity')
        
        # ç¬¬ 2 æ­¥ï¼šä½¿ç”¨è§„åˆ™æå–ç»“æ„åŒ–ä¿¡æ¯
        date_str, timeline = self.extract_time_info(extracted_text)
        place = self.extract_place_info(extracted_text)
        tags = self.extract_tags(title, extracted_text)
        
        # å¦‚æœ LLM æ²¡æœ‰æå–æè¿°ï¼Œä½¿ç”¨è§„åˆ™æå–
        if not description:
            description = self.extract_description(extracted_text)
        
        # å¦‚æœ LLM æ²¡æœ‰æå–æ ‡ç­¾ï¼Œä½¿ç”¨è§„åˆ™æå–
        if not tags:
            tags = self.extract_tags(title, extracted_text)
        
        # æ„å»ºäº‹ä»¶
        event = ActivityEvent(
            year=datetime.now().year,
            id=self._generate_id(title),
            link=source_url or '',
            date=date_str or '',
            place=place or '',
            timeline=timeline
        )
        
        # æ„å»ºæ´»åŠ¨
        activity = ParsedActivity(
            title=title,
            description=description,
            category=category,
            tags=tags,
            events=[event]
        )
        
        return activity
    
    async def _parse_with_llm(self, text: str) -> Dict:
        """ä½¿ç”¨ LLM è§£æ"""
        
        if not self.llm:
            return {"title": "æ´»åŠ¨", "description": "", "category": "activity"}
        
        prompt = f"""è¯·ä»ä»¥ä¸‹æ´»åŠ¨æ–‡æœ¬ä¸­æå–ä¿¡æ¯ï¼Œè¿”å› JSON æ ¼å¼:

æ–‡æœ¬:
{text[:1000]}

è¯·è¿”å›ä»¥ä¸‹ JSON æ ¼å¼ (ä¸è¦å…¶ä»–æ–‡å­—):
{{
  "title": "æ´»åŠ¨æ ‡é¢˜",
  "description": "æ´»åŠ¨æè¿° (æœ€å¤š100å­—)",
  "category": "conference|competition|activity"
}}
"""
        
        try:
            response = await self.llm.parse(prompt)
            import json
            if isinstance(response, str):
                result = json.loads(response)
            else:
                result = response
            return result
        except:
            return {"title": "æ´»åŠ¨", "description": "", "category": "activity"}
    
    def _generate_id(self, title: str) -> str:
        """ç”Ÿæˆæ´»åŠ¨ ID"""
        import hashlib
        hash_obj = hashlib.md5(title.encode())
        return hash_obj.hexdigest()[:8]
