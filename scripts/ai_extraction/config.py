"""
AI Agent æ´»åŠ¨æå–ç³»ç»Ÿé…ç½®æ–‡ä»¶

æ”¯æŒä¸¤ç§AIæ–¹æ¡ˆï¼š
1. GitHub Models (æ¨è - å…è´¹) - éœ€è¦GITHUB_TOKEN
2. OpenAI API (å¯é€‰ - ä»˜è´¹) - éœ€è¦OPENAI_API_KEY
"""

import os
from pathlib import Path
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    """ç³»ç»Ÿé…ç½®"""
    
    # ============ GitHub Models é…ç½® (æ¨è - å…è´¹) ============
    GITHUB_TOKEN: str = os.getenv("GITHUB_TOKEN", "")
    """GitHub Personal Access Token - ç”¨äºGitHub Models API (æ¨è)"""
    
    GITHUB_MODELS_API_BASE: str = "https://models.inference.ai.azure.com/chat/completions"
    GITHUB_MODELS_DEFAULT: str = "gpt-4o"
    
    # æ”¯æŒçš„GitHubå…è´¹æ¨¡å‹
    GITHUB_MODELS_AVAILABLE: list = [
        "gpt-4o",                    # æ¨èï¼šæœ€å¼ºèƒ½åŠ›ï¼Œé€Ÿåº¦å¿«
        "claude-3-5-sonnet",         # å¯é€‰ï¼šClaudeèƒ½åŠ›
        "phi-4",                     # å¯é€‰ï¼šè½»é‡çº§æ¨¡å‹
        "llama-3.1-405b",           # å¯é€‰ï¼šå¼€æºå¤§æ¨¡å‹
    ]
    
    # ============ OpenAI é…ç½® (å¯é€‰ - ä»˜è´¹) ============
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    """OpenAI APIå¯†é’¥ (å¯é€‰ - ä»…åœ¨GitHub Modelsä¸å¯ç”¨æ—¶ä½¿ç”¨)"""
    
    OPENAI_MODEL: str = "gpt-4-turbo-preview"  # æˆ– gpt-3.5-turbo
    OPENAI_API_BASE: str = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
    
    # ============ AIé€‰æ‹©ç­–ç•¥ ============
    # è‡ªåŠ¨é€‰æ‹©ä¼˜å…ˆçº§:
    # 1. å¦‚æœæœ‰GITHUB_TOKEN â†’ ä½¿ç”¨GitHub Models (æ¨è)
    # 2. å¦‚æœæœ‰OPENAI_API_KEY â†’ ä½¿ç”¨OpenAI (å¤‡é€‰)
    # 3. éƒ½æ²¡æœ‰ â†’ ä½¿ç”¨è§„åˆ™è§£æå™¨ (åŸºç¡€)
    
    USE_GITHUB_MODELS: bool = bool(os.getenv("GITHUB_TOKEN", ""))  # è‡ªåŠ¨æ£€æµ‹
    USE_OPENAI_FALLBACK: bool = bool(os.getenv("OPENAI_API_KEY", ""))  # è‡ªåŠ¨æ£€æµ‹
    
    # LLM è¶…å‚æ•°
    LLM_TEMPERATURE: float = 0.3  # é™ä½æ¸©åº¦ï¼Œä½¿è¾“å‡ºæ›´ç¨³å®š
    LLM_MAX_TOKENS: int = 2000
    
    # é¡¹ç›®è·¯å¾„
    PROJECT_ROOT: Path = Path(__file__).parent.parent.parent
    DATA_DIR: Path = PROJECT_ROOT / "data"
    SCRIPTS_DIR: Path = PROJECT_ROOT / "scripts"
    EXTRACTION_DIR: Path = SCRIPTS_DIR / "ai_extraction"
    PROMPTS_DIR: Path = EXTRACTION_DIR / "prompts"
    CACHE_DIR: Path = EXTRACTION_DIR / ".cache"
    TEMP_DIR: Path = EXTRACTION_DIR / ".temp"
    
    # ç½‘é¡µçˆ¬å–é…ç½®
    REQUEST_TIMEOUT: int = 30
    MAX_RETRIES: int = 3
    USER_AGENT: str = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    
    # OCR é…ç½®
    TESSERACT_CMD: str = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Windows è·¯å¾„ï¼Œæ ¹æ®å®é™…ä¿®æ”¹
    ENABLE_OCR: bool = False  # é»˜è®¤å…³é—­ï¼Œéœ€è¦æœ¬åœ°å®‰è£… Tesseract
    
    # äºŒç»´ç è¯†åˆ«
    ENABLE_QR_CODE: bool = False
    
    # æ–‡ä»¶å¤§å°é™åˆ¶ (MB)
    MAX_FILE_SIZE: int = 50
    MAX_IMAGE_SIZE: int = 10
    
    # æ•°æ®éªŒè¯é…ç½®
    VALIDATE_LINKS: bool = False  # é“¾æ¥æ£€æŸ¥å¯èƒ½è€—æ—¶è¾ƒé•¿
    DESCRIPTION_MAX_LENGTH: int = 100
    
    # GitHub é…ç½®
    GITHUB_TOKEN: str = os.getenv("GITHUB_TOKEN", "")
    GITHUB_REPO: str = "hust-open-atom-club/open-source-deadlines"
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str = "INFO"
    LOG_FILE: Path = EXTRACTION_DIR / ".logs" / "extraction.log"
    
    class Config:
        case_sensitive = True
        env_file = ".env"
        extra = "allow"
    
    def __init__(self, **data):
        super().__init__(**data)
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        for dir_path in [self.CACHE_DIR, self.TEMP_DIR, self.LOG_FILE.parent]:
            dir_path.mkdir(parents=True, exist_ok=True)


# å…¨å±€é…ç½®å®ä¾‹
settings = Settings()

# æ•°æ®æ–‡ä»¶è·¯å¾„
ACTIVITIES_FILE = settings.DATA_DIR / "activities.yml"
COMPETITIONS_FILE = settings.DATA_DIR / "competitions.yml"
CONFERENCES_FILE = settings.DATA_DIR / "conferences.yml"

# æ•°æ®æ–‡ä»¶åˆ«å
DATA_FILE_MAP = {
    "activity": ACTIVITIES_FILE,
    "competition": COMPETITIONS_FILE,
    "conference": CONFERENCES_FILE,
}

# æ—¶é—´ç›¸å…³é…ç½®
IANA_TIMEZONES = [
    "Asia/Shanghai",
    "Asia/Beijing",
    "Asia/Tokyo",
    "Asia/Seoul",
    "Asia/Singapore",
    "Asia/Hong_Kong",
    "Asia/Taipei",
    "Asia/Bangkok",
    "America/New_York",
    "America/Los_Angeles",
    "America/Chicago",
    "America/Denver",
    "Europe/London",
    "Europe/Paris",
    "Europe/Berlin",
    "Europe/Moscow",
    "UTC",
]

# æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
SUPPORTED_FORMATS = {
    "text": [".txt", ".md"],
    "web": ["http", "https"],
    "document": [".pdf"],
    "image": [".jpg", ".jpeg", ".png", ".gif", ".webp"],
}

def print_config_info():
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("\n" + "="*60)
    print("âš™ï¸  ç³»ç»Ÿé…ç½®ä¿¡æ¯")
    print("="*60)
    
    if settings.USE_GITHUB_MODELS:
        print(f"\nâœ“ AIæ–¹æ¡ˆ: GitHub Models (å…è´¹)")
        print(f"  Token: {settings.GITHUB_TOKEN[:15]}...***")
        print(f"  é»˜è®¤æ¨¡å‹: {settings.GITHUB_MODELS_DEFAULT}")
        print(f"  å¯ç”¨æ¨¡å‹: {', '.join(settings.GITHUB_MODELS_AVAILABLE)}")
    elif settings.USE_OPENAI_FALLBACK:
        print(f"\nâš   AIæ–¹æ¡ˆ: OpenAI (ä»˜è´¹å¤‡é€‰)")
        print(f"  API Key: {settings.OPENAI_API_KEY[:15]}...***")
        print(f"  æ¨¡å‹: {settings.OPENAI_MODEL}")
    else:
        print(f"\nâŒ AIæ–¹æ¡ˆ: æœªé…ç½®ä»»ä½•AIæœåŠ¡")
        print(f"  å°†ä½¿ç”¨è§„åˆ™è§£æå™¨ (åŠŸèƒ½å—é™)")
    
    print(f"\nğŸ“ é¡¹ç›®ç›®å½•: {settings.PROJECT_ROOT}")
    print(f"ğŸ“Š æ•°æ®ç›®å½•: {settings.DATA_DIR}")
    print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {settings.CACHE_DIR}")
    print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {settings.LOG_FILE}")
    print("="*60 + "\n")


def validate_config():
    """éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®"""
    print("\n" + "="*60)
    print("ğŸ” é…ç½®éªŒè¯")
    print("="*60)
    
    if settings.USE_GITHUB_MODELS:
        if not settings.GITHUB_TOKEN:
            print("âŒ å·²å¯ç”¨GitHub Modelsä½†æœªé…ç½®GITHUB_TOKEN")
            return False
        print("âœ“ GitHub Tokenå·²é…ç½® (æ¨è)")
    
    if settings.USE_OPENAI_FALLBACK:
        if not settings.OPENAI_API_KEY:
            print("âŒ å·²å¯ç”¨OpenAIä½†æœªé…ç½®OPENAI_API_KEY")
            return False
        print("âœ“ OpenAI API Keyå·²é…ç½® (å¤‡é€‰)")
    
    if not settings.USE_GITHUB_MODELS and not settings.USE_OPENAI_FALLBACK:
        print("âš ï¸  æœªé…ç½®ä»»ä½•AIæœåŠ¡ï¼Œå°†ä½¿ç”¨è§„åˆ™è§£æå™¨")
        print("\nå»ºè®®é…ç½®:")
        print("  1. GITHUB_TOKEN (æ¨è - å…è´¹)")
        print("  2. OPENAI_API_KEY (å¯é€‰ - ä»˜è´¹)")
        return True  # ä»ç„¶å¯ä»¥è¿è¡Œï¼Œåªæ˜¯åŠŸèƒ½å—é™
    
    print("="*60 + "\n")
    return True


if __name__ == "__main__":
    print_config_info()
    validate_config()
    print(f"\né¡¹ç›®æ ¹ç›®å½•: {settings.PROJECT_ROOT}")
    print(f"æ•°æ®ç›®å½•: {settings.DATA_DIR}")
    print(f"æ´»åŠ¨æ•°æ®æ–‡ä»¶: {ACTIVITIES_FILE}")
    print(f"ç«èµ›æ•°æ®æ–‡ä»¶: {COMPETITIONS_FILE}")
    print(f"ä¼šè®®æ•°æ®æ–‡ä»¶: {CONFERENCES_FILE}")
    print(f"ç¼“å­˜ç›®å½•: {settings.CACHE_DIR}")
