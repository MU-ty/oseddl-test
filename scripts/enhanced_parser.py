"""
å¢å¼ºå‹æ•°æ®è§£æå™¨ - è§„åˆ™ + LLM æ··åˆæå–
ä¼˜å…ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¶é—´ã€åœ°ç‚¹ã€é“¾æ¥ç­‰ç»“æ„åŒ–æ•°æ®
ç„¶åä½¿ç”¨ LLM è¡¥å……æè¿°ã€æ ‡ç­¾ç­‰éç»“æ„åŒ–æ•°æ®
"""

import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum

class ActivityCategory(str, Enum):
    """æ´»åŠ¨åˆ†ç±»"""
    CONFERENCE = "conference"
    COMPETITION = "competition"
    ACTIVITY = "activity"

@dataclass
class TimelineEvent:
    deadline: str
    comment: str
    
    def to_dict(self) -> Dict:
        return {"deadline": self.deadline, "comment": self.comment}

@dataclass
class ActivityEvent:
    year: int
    id: str
    link: str
    timeline: List[TimelineEvent] = field(default_factory=list)
    timezone: str = "Asia/Shanghai"
    date: str = ""
    place: str = ""
    
    def to_dict(self) -> Dict:
        return {
            "year": self.year,
            "id": self.id,
            "link": self.link,
            "timeline": [t.to_dict() for t in self.timeline],
            "timezone": self.timezone,
            "date": self.date,
            "place": self.place
        }

@dataclass
class ParsedActivity:
    title: str
    description: str
    category: Union[ActivityCategory, str]
    tags: List[str] = field(default_factory=list)
    events: List[ActivityEvent] = field(default_factory=list)
    
    def to_dict(self) -> Dict:
        return {
            "title": self.title,
            "description": self.description,
            "category": self.category.value if isinstance(self.category, ActivityCategory) else self.category,
            "tags": self.tags,
            "events": [e.to_dict() for e in self.events]
        }
    
    def to_yaml_str(self) -> str:
        """è½¬æ¢ä¸ºYAMLæ ¼å¼å­—ç¬¦ä¸²"""
        try:
            import yaml
            data = self.to_dict()
            return yaml.dump([data], allow_unicode=True, sort_keys=False, default_flow_style=False)
        except:
            import json
            return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)

class EnhancedDataParser:
    """å¢å¼ºçš„æ•°æ®è§£æå™¨ - è§„åˆ™ + LLM"""
    
    def __init__(self):
        self.llm = None
        try:
            from github_models_parser import GitHubModelsParser
            from config import settings
            self.llm = GitHubModelsParser(settings.GITHUB_TOKEN, model="gpt-4o")
        except:
            pass
    
    def extract_time_info(self, text: str) -> Tuple[Optional[str], List[TimelineEvent]]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¶é—´ä¿¡æ¯ï¼Œè¿”å›æ—¥æœŸå’Œæ—¶é—´çº¿äº‹ä»¶"""
        
        # ä¼˜å…ˆçº§ 1: å®Œæ•´æ—¶é—´æ®µ "2025å¹´11æœˆ1æ—¥ï¼ˆæ˜ŸæœŸå…­ï¼‰09:00-18:00" æˆ– "2025å¹´11æœˆ11æ—¥ 09:30-11:30"
        time_range_patterns = [
            # æ ¼å¼: 2025å¹´11æœˆ1æ—¥ï¼ˆæ˜ŸæœŸå…­ï¼‰09:00-18:00
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥(?:[ï¼ˆ(].*?[ï¼‰)])?\s*(\d{1,2}):(\d{2})\s*[-~]\s*(\d{1,2}):(\d{2})',
            # æ ¼å¼: 2025-11-01 09:00-18:00
            r'(\d{4})-(\d{1,2})-(\d{1,2})[T\s]+(\d{1,2}):(\d{2})\s*[-~]\s*(\d{1,2}):(\d{2})',
            # æ ¼å¼: 2025å¹´11æœˆ11æ—¥ 09:30-11:30
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥\s+(\d{1,2}):(\d{2})\s*[-~]\s*(\d{1,2}):(\d{2})',
        ]
        
        timeline = []
        date_str = None
        
        for pattern in time_range_patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    year, month, day, h1, m1, h2, m2 = [int(g) for g in match.groups()]
                    date_str = f"{year}-{month:02d}-{day:02d}"
                    
                    # æ·»åŠ å¼€å§‹æ—¶é—´ç‚¹
                    start_time = f"{year}-{month:02d}-{day:02d}T{h1:02d}:{m1:02d}:00"
                    timeline.append(TimelineEvent(
                        deadline=start_time,
                        comment='æ´»åŠ¨å¼€å§‹'
                    ))
                    
                    # æ·»åŠ ç»“æŸæ—¶é—´ç‚¹
                    end_time = f"{year}-{month:02d}-{day:02d}T{h2:02d}:{m2:02d}:00"
                    timeline.append(TimelineEvent(
                        deadline=end_time,
                        comment='æ´»åŠ¨ç»“æŸ'
                    ))
                    
                    return date_str, timeline
                except Exception as e:
                    pass
        
        # ä¼˜å…ˆçº§ 2: ISO 8601 æ ¼å¼æ—¶é—´èŒƒå›´ "2025-11-01T09:00:00 - 2025-11-01T18:00:00"
        iso_range_pattern = r'(\d{4})-(\d{1,2})-(\d{1,2})T(\d{1,2}):(\d{2}):(\d{2})\s*[-~]\s*(\d{4})-(\d{1,2})-(\d{1,2})T(\d{1,2}):(\d{2}):(\d{2})'
        iso_match = re.search(iso_range_pattern, text)
        if iso_match:
            try:
                s_year, s_month, s_day, s_hour, s_min, s_sec, e_year, e_month, e_day, e_hour, e_min, e_sec = \
                    [int(g) for g in iso_match.groups()]
                
                date_str = f"{s_year}-{s_month:02d}-{s_day:02d}"
                
                timeline = [
                    TimelineEvent(
                        deadline=f"{s_year}-{s_month:02d}-{s_day:02d}T{s_hour:02d}:{s_min:02d}:{s_sec:02d}",
                        comment='æ´»åŠ¨å¼€å§‹'
                    ),
                    TimelineEvent(
                        deadline=f"{e_year}-{e_month:02d}-{e_day:02d}T{e_hour:02d}:{e_min:02d}:{e_sec:02d}",
                        comment='æ´»åŠ¨ç»“æŸ'
                    )
                ]
                return date_str, timeline
            except:
                pass
        
        # ä¼˜å…ˆçº§ 3: åˆ†åˆ«çš„å¼€å§‹å’Œç»“æŸæ—¶é—´
        start_pattern = r'(?:å¼€å§‹|start)[ï¼š:]\s*(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥[ï¼Œ,\s]+(\d{1,2}):(\d{2})'
        end_pattern = r'(?:ç»“æŸ|end)[ï¼š:]\s*(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥[ï¼Œ,\s]+(\d{1,2}):(\d{2})'
        
        start_match = re.search(start_pattern, text)
        end_match = re.search(end_pattern, text)
        
        if start_match and end_match:
            try:
                s_year, s_month, s_day, s_hour, s_min = [int(g) for g in start_match.groups()]
                e_year, e_month, e_day, e_hour, e_min = [int(g) for g in end_match.groups()]
                
                date_str = f"{s_year}-{s_month:02d}-{s_day:02d}"
                
                timeline = [
                    TimelineEvent(
                        deadline=f"{s_year}-{s_month:02d}-{s_day:02d}T{s_hour:02d}:{s_min:02d}:00",
                        comment='æ´»åŠ¨å¼€å§‹'
                    ),
                    TimelineEvent(
                        deadline=f"{e_year}-{e_month:02d}-{e_day:02d}T{e_hour:02d}:{e_min:02d}:00",
                        comment='æ´»åŠ¨ç»“æŸ'
                    )
                ]
                return date_str, timeline
            except:
                pass
        
        # ä¼˜å…ˆçº§ 4: åªæœ‰æ—¥æœŸ "YYYYå¹´MMæœˆDDæ—¥"
        if not timeline:
            single_time_patterns = [
                r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥(?![0-9:])',
                r'(\d{4})-(\d{1,2})-(\d{1,2})(?![T0-9:])',
                r'time[ï¼š:]\s*(\d{4})-(\d{1,2})-(\d{1,2})',
            ]
            
            for pattern in single_time_patterns:
                match = re.search(pattern, text)
                if match:
                    try:
                        year, month, day = [int(g) for g in match.groups()[:3]]
                        date_str = f"{year}-{month:02d}-{day:02d}"
                        timeline.append(TimelineEvent(
                            deadline=f"{date_str}T00:00:00",
                            comment='å…³é”®æ—¥æœŸ'
                        ))
                        return date_str, timeline
                    except:
                        pass
        
        return date_str, timeline
    
    def extract_place_info(self, text: str) -> Optional[str]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–åœ°ç‚¹ä¿¡æ¯ï¼Œå¹¶æ¸…ç†æ— å…³ä¿¡æ¯"""
        
        patterns = [
            r'(?:åœ°ç‚¹|åœ°å€|ä¸¾åŠåœ°ç‚¹|ä¸¾åŠåœ°)[ï¼š:]\s*([^\nã€‚ï¼Œï¼›ï¼›\|]+)',
            r'(?:Location|Place)[ï¼š:]\s*([^\nã€‚ï¼Œï¼›ï¼›\|]+)',
            r'ğŸ“\s*([^\nã€‚ï¼Œï¼›ï¼›\|]+)',
        ]
        
        place = None
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                place = match.group(1).strip()
                break
        
        if not place:
            return None
        
        # æ¸…ç†æ— å…³ä¿¡æ¯
        remove_keywords = [
            r'æ¨è.*?(?=\s*[ï¼Œï¼›ï¼›]|$)',  # æ¨èåœè½¦ä½ç­‰
            r'[ï¼Œï¼›ï¼›]\s*(?:åœè½¦|åœ°é“|å…¬äº¤|åœ°é“çº¿è·¯|å…¬äº¤è½¦|è·ç¦»|é™„è¿‘|æ¨è|æ­¥è¡Œ|å¼€è½¦|ä¹˜å).*?(?=\s*[ï¼Œï¼›ï¼›]|$)',
            r'[ï¼Œï¼›ï¼›]\s*\d+å…ƒ/å°æ—¶.*?(?=\s*[ï¼Œï¼›ï¼›]|$)',
            r'[ï¼Œï¼›ï¼›]\s*\d+(?:å·çº¿|è·¯|ç±³).*?(?=\s*[ï¼Œï¼›ï¼›]|$)',
            r'ç‚¹å‡»æŠ¥å.*?$',
            r'é•¿æŒ‰.*?$',
            r'æ‰«æ.*?$',
        ]
        
        for pattern in remove_keywords:
            place = re.sub(pattern, '', place, flags=re.IGNORECASE)
        
        place = place.strip()
        place = re.sub(r'[ï¼Œï¼›ï¼›]$', '', place)
        
        # é™åˆ¶é•¿åº¦å¹¶éªŒè¯
        if place and len(place) > 3:
            place = place[:80]
            if re.search(r'[\u4e00-\u9fa5a-zA-Z]+', place):
                return place
        
        return None
    
    def extract_description(self, text: str) -> str:
        """æå–æ´»åŠ¨æè¿°"""
        
        # å–å‰ 200 ä¸ªå­—ç¬¦ä½œä¸ºæè¿°
        lines = text.split('\n')
        description = ''
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('æ—¶é—´') and not line.startswith('åœ°ç‚¹'):
                description += line + ' '
                if len(description) > 200:
                    break
        
        return description[:300] if description else 'æ´»åŠ¨ä¿¡æ¯'
    
    def extract_tags(self, title: str, text: str) -> List[str]:
        """è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾"""
        
        tags = []
        
        # åŸºäºæ ‡é¢˜å’Œå†…å®¹çš„å…³é”®è¯
        keywords = {
            'å¼€æº': ['å¼€æº', 'open source', 'opensource'],
            'æ ¡å›­': ['å¤§å­¦', 'é«˜æ ¡', 'æ ¡å›­', 'university', 'campus'],
            'ä¼šè®®': ['ä¼šè®®', 'conference', 'summit'],
            'ç«èµ›': ['ç«èµ›', 'competition', 'æ¯”èµ›', 'contest'],
            'è®²åº§': ['è®²åº§', 'talk', 'seminar'],
            'å·¥ä½œåŠ': ['å·¥ä½œåŠ', 'workshop', 'ç ”è®¨'],
        }
        
        combined_text = (title + ' ' + text).lower()
        
        for tag, keywords_list in keywords.items():
            for keyword in keywords_list:
                if keyword.lower() in combined_text:
                    tags.append(tag)
                    break
        
        return list(set(tags))[:5]  # æœ€å¤š 5 ä¸ªæ ‡ç­¾
    
    async def parse(self, extracted_text: str, source_url: str = None) -> ParsedActivity:
        """
        è§£ææå–çš„æ–‡æœ¬
        """
        
        # ç¬¬ 1 æ­¥ï¼šä½¿ç”¨ LLM è·å–æ ‡é¢˜å’Œåˆ†ç±»
        llm_result = await self._parse_with_llm(extracted_text)
        
        title = llm_result.get('title', 'æ´»åŠ¨')
        description = llm_result.get('description', '')
        category_str = llm_result.get('category', 'activity')
        
        # ç¡®ä¿ category æ˜¯æœ‰æ•ˆçš„ Enum å€¼
        try:
            category = ActivityCategory(category_str)
        except (ValueError, KeyError):
            category = ActivityCategory.ACTIVITY
        
        # ç¬¬ 2 æ­¥ï¼šä½¿ç”¨è§„åˆ™æå–ç»“æ„åŒ–ä¿¡æ¯
        date_str, timeline = self.extract_time_info(extracted_text)
        place = self.extract_place_info(extracted_text)
        tags = self.extract_tags(title, extracted_text)
        
        # å¦‚æœ LLM æ²¡æœ‰æå–æè¿°ï¼Œä½¿ç”¨è§„åˆ™æå–
        if not description:
            description = self.extract_description(extracted_text)
        
        # å¦‚æœ LLM æ²¡æœ‰æå–æ ‡ç­¾ï¼Œä½¿ç”¨è§„åˆ™æå–
        if not tags:
            tags = self.extract_tags(title, extracted_text)
        
        # æ„å»ºäº‹ä»¶
        event = ActivityEvent(
            year=datetime.now().year,
            id=self._generate_id(title),
            link=source_url or '',
            date=date_str or '',
            place=place or '',
            timeline=timeline
        )
        
        # æ„å»ºæ´»åŠ¨
        activity = ParsedActivity(
            title=title,
            description=description,
            category=category,
            tags=tags,
            events=[event]
        )
        
        return activity
    
    async def _parse_with_llm(self, text: str) -> Dict:
        """ä½¿ç”¨ LLM è§£æ"""
        
        if not self.llm:
            return {"title": "æ´»åŠ¨", "description": "", "category": "activity"}
        
        prompt = f"""è¯·ä»ä»¥ä¸‹æ´»åŠ¨æ–‡æœ¬ä¸­æå–ä¿¡æ¯ï¼Œè¿”å› JSON æ ¼å¼:

æ–‡æœ¬:
{text[:1000]}

è¯·è¿”å›ä»¥ä¸‹ JSON æ ¼å¼ (ä¸è¦å…¶ä»–æ–‡å­—):
{{
  "title": "æ´»åŠ¨æ ‡é¢˜",
  "description": "æ´»åŠ¨æè¿° (æœ€å¤š100å­—)",
  "category": "conference|competition|activity"
}}
"""
        
        try:
            response = await self.llm.parse(prompt)
            import json
            if isinstance(response, str):
                result = json.loads(response)
            else:
                result = response
            return result
        except:
            return {"title": "æ´»åŠ¨", "description": "", "category": "activity"}
    
    def _generate_id(self, title: str) -> str:
        """ç”Ÿæˆæ´»åŠ¨ ID"""
        import hashlib
        hash_obj = hashlib.md5(title.encode())
        return hash_obj.hexdigest()[:8]
