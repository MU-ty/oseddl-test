"""
å¢å¼ºçš„å·¥ä½œæµæå–è„šæœ¬ - ä¸“ä¸º GitHub Actions ä¼˜åŒ–
- æå–æ—¶é—´ã€åœ°ç‚¹ã€é“¾æ¥ã€æè¿°ç­‰å®Œæ•´ä¿¡æ¯
- æ›´å¥½çš„é”™è¯¯å¤„ç†
- è¯¦ç»†çš„æ—¥å¿—è¾“å‡º
"""

import asyncio
import json
import logging
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ è„šæœ¬ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def extract_activity_workflow(input_data: str) -> dict:
    """
    å·¥ä½œæµä¸“ç”¨çš„æå–å‡½æ•°
    
    Args:
        input_data: URL æˆ–æ–‡æœ¬è¾“å…¥
    
    Returns:
        åŒ…å«æå–ç»“æœçš„å­—å…¸
    """
    
    result = {
        "success": False,
        "error": None,
        "comment": "",
        "data": {}
    }
    
    try:
        if not input_data or not input_data.strip():
            result["error"] = "æœªæä¾›æœ‰æ•ˆçš„è¾“å…¥ï¼ˆURLæˆ–æ–‡æœ¬ï¼‰"
            result["comment"] = "âŒ æœªæä¾›æœ‰æ•ˆçš„URLæˆ–æ–‡æœ¬\n\nè¯·åœ¨å‘½ä»¤åæä¾›URLæˆ–æ´»åŠ¨ä¿¡æ¯ï¼Œä¾‹å¦‚:\n`@bot extract https://example.com`"
            return result
        
        logger.info(f"å¼€å§‹æå–: {input_data[:50]}...")
        
        # å¯¼å…¥æå–æ¨¡å—
        try:
            from information_extraction import InformationExtractor
            from data_parsing import DataParser
            from data_validation import DataValidator
            from result_feedback import generate_issue_comment
            logger.info("âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            logger.error(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            result["error"] = f"æ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}"
            result["comment"] = f"âŒ ä¾èµ–æ¨¡å—ç¼ºå¤±\n\n{str(e)}"
            return result
        
        # ç¬¬ 1 æ­¥ï¼šä¿¡æ¯æå–
        logger.info("ç¬¬1æ­¥: æå–ä¿¡æ¯...")
        extractor = InformationExtractor(enable_ocr=False)
        
        try:
            extraction = await extractor.extract(input_data)
            logger.info(f"âœ“ æå–æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(extraction.extracted_text)}")
            
            if not extraction.extracted_text:
                result["error"] = "æ— æ³•ä»è¾“å…¥æºæå–ä»»ä½•æ–‡æœ¬"
                result["comment"] = "âŒ æå–å¤±è´¥\n\næ— æ³•ä»æä¾›çš„URLæˆ–æ–‡æœ¬ä¸­æå–ä»»ä½•å†…å®¹ã€‚\n\nè¯·ç¡®ä¿:\n1. URL å¯è®¿é—®\n2. URL æŒ‡å‘çš„é¡µé¢åŒ…å«æ´»åŠ¨ä¿¡æ¯\n3. æˆ–æä¾›è¶³å¤Ÿçš„æ´»åŠ¨æ–‡æœ¬æè¿°"
                return result
        
        except Exception as e:
            logger.error(f"æå–å¤±è´¥: {e}")
            result["error"] = f"æå–å¤±è´¥: {str(e)}"
            result["comment"] = f"âŒ æå–å¤±è´¥\n\n{str(e)}"
            return result
        
        # ç¬¬ 2 æ­¥ï¼šæ•°æ®è§£æ
        logger.info("ç¬¬2æ­¥: è§£ææ•°æ®...")
        parser = DataParser(use_github_models=True)
        
        try:
            activity = await parser.parse(extraction.extracted_text)
            logger.info(f"âœ“ è§£ææˆåŠŸ: {activity.title}")
        
        except Exception as e:
            logger.error(f"è§£æå¤±è´¥: {e}")
            result["error"] = f"è§£æå¤±è´¥: {str(e)}"
            result["comment"] = f"âŒ æ•°æ®è§£æå¤±è´¥\n\n{str(e)}\n\nè¯·æ£€æŸ¥æå–çš„å†…å®¹æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ´»åŠ¨ä¿¡æ¯ã€‚"
            return result
        
        # ç¬¬ 3 æ­¥ï¼šæ•°æ®éªŒè¯
        logger.info("ç¬¬3æ­¥: éªŒè¯æ•°æ®...")
        validator = DataValidator()
        
        try:
            validation = validator.validate(activity)
            logger.info(f"âœ“ éªŒè¯å®Œæˆ: {len(validation.passed)} é€šè¿‡, {len(validation.warnings)} è­¦å‘Š")
        
        except Exception as e:
            logger.error(f"éªŒè¯å¤±è´¥: {e}")
            # éªŒè¯å¤±è´¥ä¸æ˜¯è‡´å‘½é”™è¯¯ï¼Œç»§ç»­å¤„ç†
            validation = None
        
        # ç¬¬ 4 æ­¥ï¼šç”Ÿæˆå›å¤
        logger.info("ç¬¬4æ­¥: ç”Ÿæˆå›å¤...")
        try:
            comment = generate_issue_comment(extraction, activity, validation)
            logger.info("âœ“ å›å¤ç”ŸæˆæˆåŠŸ")
        
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {e}")
            # ç”Ÿæˆé»˜è®¤å›å¤
            comment = format_default_comment(activity, extraction)
        
        # æˆåŠŸï¼
        result["success"] = True
        result["comment"] = comment
        result["data"] = {
            "title": activity.title,
            "description": activity.description,
            "category": activity.category.value if hasattr(activity.category, 'value') else str(activity.category),
            "tags": activity.tags,
            "events": [e.to_dict() for e in activity.events] if activity.events else [],
            "source_url": input_data if input_data.startswith('http') else None,
            "source_text": extraction.extracted_text[:200] + "..." if len(extraction.extracted_text) > 200 else extraction.extracted_text
        }
        
        logger.info("âœ“ å®Œæˆï¼")
    
    except Exception as e:
        logger.exception(f"æœªé¢„æœŸçš„é”™è¯¯: {e}")
        result["error"] = str(e)
        result["comment"] = f"âŒ å‡ºç°æœªé¢„æœŸçš„é”™è¯¯\n\n```\n{str(e)}\n```"
    
    return result


def format_default_comment(activity, extraction) -> str:
    """ç”Ÿæˆé»˜è®¤çš„å›å¤è¯„è®º"""
    
    comment = f"""âœ… **æ´»åŠ¨ä¿¡æ¯æå–æˆåŠŸ**

ğŸ“Œ **æ´»åŠ¨æ ‡é¢˜:** {activity.title}

ğŸ“‚ **åˆ†ç±»:** {activity.category.value if hasattr(activity.category, 'value') else activity.category}

ğŸ“ **æè¿°:** 
{activity.description[:200] + '...' if len(activity.description) > 200 else activity.description}

ğŸ·ï¸ **æ ‡ç­¾:** {', '.join(activity.tags) if activity.tags else '(æ— )'}

â° **æ—¶é—´å®‰æ’:**
"""
    
    if activity.events:
        for event in activity.events[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªäº‹ä»¶
            comment += f"\n- å¹´ä»½: {event.year}\n"
            if event.date:
                comment += f"  æ—¥æœŸ: {event.date}\n"
            if event.place:
                comment += f"  åœ°ç‚¹: {event.place}\n"
            if event.timeline:
                comment += f"  {len(event.timeline)} ä¸ªæ—¶é—´èŠ‚ç‚¹\n"
    else:
        comment += "\n(æœªè¯†åˆ«åˆ°å…·ä½“æ—¶é—´)"
    
    comment += f"""

ğŸ“Š **æå–ç»Ÿè®¡:**
- åŸå§‹æ–‡æœ¬é•¿åº¦: {len(extraction.extracted_text)} å­—ç¬¦
- æå–æ—¶é—´: {extraction.extraction_timestamp}
- æºç±»å‹: {extraction.source_type.value if hasattr(extraction.source_type, 'value') else extraction.source_type}

---
*ç”± GitHub Actions è‡ªåŠ¨æå–*
"""
    
    return comment


async def main():
    """ä¸»å‡½æ•°"""
    
    # ä»å‘½ä»¤è¡Œå‚æ•°æˆ–ç¯å¢ƒå˜é‡è·å–è¾“å…¥
    input_data = sys.argv[1] if len(sys.argv) > 1 else None
    
    if not input_data:
        print(json.dumps({
            "success": False,
            "error": "æœªæä¾›è¾“å…¥å‚æ•°"
        }, ensure_ascii=False, indent=2))
        return
    
    # æ‰§è¡Œæå–
    result = await extract_activity_workflow(input_data)
    
    # è¾“å‡ºç»“æœä¸º JSON
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    asyncio.run(main())
